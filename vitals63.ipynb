{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca87711d-b17c-4fdf-8662-d72449c81ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "<>:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "/var/folders/pc/6rmkz3b536l1k66dbrhqbl2r0000gn/T/ipykernel_33095/3605166121.py:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n",
      "/var/folders/pc/6rmkz3b536l1k66dbrhqbl2r0000gn/T/ipykernel_33095/3605166121.py:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Read the Input File and convert to pandas dataframe\u001b[39;00m\n\u001b[1;32m     14\u001b[0m input_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPIC/Input.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df_input \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43minput_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mheader)\n\u001b[1;32m     16\u001b[0m df_input\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "# Defining the input file header\n",
    "\n",
    "header=['PatientID', 'PatientMRN', 'LastName', 'FirstName', 'MiddleName', 'DateofBirth', 'Sex', 'Metric_Desc', 'Metric_Abbr', 'Result', 'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue', 'QOCClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue', 'NumericFinding', 'Unit_Abbr', 'RecordedDTTM', 'QODE', 'Vital_Status', 'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode', 'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name', 'APM_Patient_Last_Name', 'APM_Patient_MI', 'APM_Patient_Street1', 'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State', 'APM_Patient_Zip_Code', 'APM_Patient_Country', 'APM_Patient_Sex', 'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone', 'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type', 'Patient_Primary_Phone_Number', 'Patient_Email']\n",
    "# Read the Input File and convert to pandas dataframe\n",
    "input_files = glob.glob('EPIC/Input.txt')\n",
    "df_input = pd.read_csv(input_files[0], delimiter='|', header=None, names=header)\n",
    "df_input.fillna('', inplace=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the Input File and convert to pandas dataframe\n",
    "\n",
    "input_files = glob.glob('EPIC/Vitals_allscript.csv')\n",
    "Vitals_allscript_df = pd.read_csv(input_files[0], delimiter=',',)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Vitals_allscript_df.head(5)\n",
    "# df_input.columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Apply strptime to each element of the 'CreateDTTM' column\n",
    "df_input['reformated_CreateDTTM'] = pd.to_datetime(df_input['CreateDTTM'], format='%Y-%m-%d %H:%M:%S.%f').dt.strftime('%m-%d-%Y %H:%M')\n",
    "\n",
    "# Convert 'reformated_CreateDTTM' back to datetime objects\n",
    "df_input['reformated_CreateDTTM'] = pd.to_datetime(df_input['reformated_CreateDTTM'], format='%m-%d-%Y %H:%M')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_input.head()\n",
    "df_input['DateOfBirth'] = df_input['DateofBirth'].str.replace('-', '', regex=False)\n",
    "df_input['CreateDTTM_converted'] = df_input['CreateDTTM'].str.replace('-', '', regex=False).str.replace(' ', '', regex=False).str.replace(':', '', regex=False).str.replace('.', '', regex=False).str[:-3]\n",
    "\n",
    "\n",
    "\n",
    "lookup_table = {\n",
    "\n",
    "    #MSH Segment\n",
    "    \"MSH-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-3\": {\"Source Column\": None, \"Default Value\": \"TouchWorks\"},\n",
    "    \"MSH-4\": {\"Source Column\": None, \"Default Value\": \"MountainWest\"},\n",
    "    \"MSH-5\": {\"Source Column\": None, \"Default Value\": \"Rhapsody^Rhapsody\"},\n",
    "    \"MSH-6\": {\"Source Column\": None, \"Default Value\": \"Epic^Epic\"},\n",
    "    \"MSH-7\": {\"Source Column\": None, \"Default Value\": datetime.now().strftime(\"%Y%m%d%H%M%S\")},\n",
    "    \"MSH-8\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-9\": {\"Source Column\": None, \"Default Value\": \"ORU^R01\"},\n",
    "    \"MSH-10\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-11\": {\"Source Column\": None, \"Default Value\": \"P\"},\n",
    "    \"MSH-12\": {\"Source Column\": None, \"Default Value\": \"2.5.1\"},\n",
    "\n",
    "\n",
    "\n",
    "    #PID segment\n",
    "\n",
    "    \"PID-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.1\": {\"Source Column\": \"PatientMRN\", \"Default Value\": None},\n",
    "    \"PID-3.2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.3\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.5\": {\"Source Column\": None, \"Default Value\": \"TWSMAMRN\"},\n",
    "    \"PID-4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-5.1\": {\"Source Column\": \"LastName\", \"Default Value\": None},\n",
    "    \"PID-5.2\": {\"Source Column\": \"FirstName\", \"Default Value\": None},\n",
    "    \"PID-5.3\": {\"Source Column\": \"MiddleName\", \"Default Value\": None},\n",
    "    \"PID-6\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-7\": {\"Source Column\": \"DateOfBirth\", \"Default Value\": None},\n",
    "    \"PID-8\": {\"Source Column\": \"Sex\", \"Default Value\": None},\n",
    "    \"PID-9\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-10\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-11\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-12\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-13\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-14\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-15\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-16\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-17\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-18\": {\"Source Column\": None, \"Default Value\": None},\n",
    "\n",
    "\n",
    "    #OBR segment\n",
    "\n",
    "    \"OBR-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-3\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-5\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-6\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-7\": {\"Source Column\": \"RecordedDTTM\", \"Default Value\": None},\n",
    "\n",
    "\n",
    "    #OBX segment\n",
    "\n",
    "    \"OBX-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-3\": {\"Source Column\": \"Metric_Abbr\", \"Default Value\": None},\n",
    "    \"OBX-4\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-5\": {\"Source Column\": \"Result\", \"Default Value\": None},\n",
    "    \"OBX-6\": {\"Source Column\": \"Unit_Abbr\", \"Default Value\": None},\n",
    "    \"OBX-7\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-8\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-9\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-10\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-11\": {\"Source Column\":None, \"Default Value\": None},\n",
    "    \"OBX-12\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-13\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-14\":{\"Source Column\":\"?\",\"Default Value\":None}\n",
    "}\n",
    "\n",
    "def convert_to_int(value):\n",
    "\n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except (ValueError, TypeError):\n",
    "        return value\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "def get_value(field, row):\n",
    "\n",
    "      source_column = lookup_table[field][\"Source Column\"]\n",
    "      default_value = lookup_table[field][\"Default Value\"]\n",
    "\n",
    "      if source_column:\n",
    "          if isinstance(source_column, list):\n",
    "              return \"_\".join([str(row.get(col, '')) for col in source_column])\n",
    "          return row.get(source_column, default_value)\n",
    "      return default_value\n",
    "\n",
    "def parse_to_hl7(df_input, lookup_table):\n",
    "\n",
    "    hl7_lines = []\n",
    "    obx_counter = {}\n",
    "    obr_counter = {}\n",
    "    empty_list = []\n",
    "    count = 0\n",
    "\n",
    "    for index, row in df_input.iterrows():\n",
    "\n",
    "      PatientMRN= row['PatientMRN']\n",
    "      if PatientMRN not in obr_counter:\n",
    "            obr_counter[PatientMRN] = 1\n",
    "      else:\n",
    "            obr_counter[PatientMRN] += 1\n",
    "\n",
    "      #Create MSH segment\n",
    "\n",
    "      msh_segment = [\n",
    "          f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n",
    "\n",
    "              ]\n",
    "\n",
    "      # Create PID segment\n",
    "      pid_segment = [\n",
    "                  f\"PID|||{get_value('PID-3.1', row)}^^^^{get_value('PID-3.5', row)}||{get_value('PID-5.1', row)}^{get_value('PID-5.2', row)}||{get_value('PID-7', row)}|{get_value('PID-8', row)}\"\n",
    "\n",
    "                  ]\n",
    "      # Create OBR segment\n",
    "      obr_segment = [\n",
    "\n",
    "                  f\"OBR|{obr_counter[PatientMRN]}||||||{get_value('OBR-3', row)}|||||||||{convert_to_int(get_value('OBR-7', row))}\"\n",
    "\n",
    "              ]\n",
    "        \n",
    "      obx_segment = [\n",
    "            f\"OBX|{obx_counter[RecordedDTTM]}||{row_get('LoincLabCode', row)}^{row_get('Metric_Abbr', row)}^LN||{row_get('Result', row)}|{row_get('Unit_Abbr', row)}\"\n",
    "        ]\n",
    "\n",
    "      hl7_message = \"\\n\".join(msh_segment + pid_segment + obr_segment + obx_segment)\n",
    "\n",
    "      hl7_lines.append(hl7_message)\n",
    "\n",
    "    return hl7_lines\n",
    "# Parse the input DataFrame to HL7 formatted output\n",
    "\n",
    "hl7_output = parse_to_hl7(df_input, lookup_table)\n",
    "# hl7_output\n",
    "\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    sanitized = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
    "    sanitized = sanitized.replace(' ', '_')\n",
    "    return sanitized\n",
    "\n",
    "\n",
    "def remove_duplicate_segments(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    unique_segments = {'MSH': False, 'PID': False, 'ORC': False, 'OBR': False}\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            segment_type = line.split('|')[0]\n",
    "            if segment_type in unique_segments:\n",
    "                if not unique_segments[segment_type]:\n",
    "                    file.write(line)\n",
    "                    unique_segments[segment_type] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "for index, row in df_input.iterrows():\n",
    "    filename = f\"{row['PatientMRN']}\"\n",
    "    sanitized_filename = sanitize_filename(filename)\n",
    "    file_path = f\"EPIC/{sanitized_filename}.hl7\"\n",
    "    file_paths.append(file_path)\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in hl7_output:\n",
    "                file.write(line + \"\\n\")\n",
    "\n",
    "for file_path in set(file_paths):\n",
    "    remove_duplicate_segments(file_path)\n",
    "\n",
    "\n",
    "\n",
    "print(hl7_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96edc0-45ab-4aea-b781-137cdd3507b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b055810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been generated and saved to output.csv\n",
      "HL7 messages have been written to 'output_hl7.txt'.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Paths for input and output files\n",
    "header_file_path = 'header.txt'  # Path to header.txt\n",
    "input_file_path = 'Input.txt'  # Path to Input.txt\n",
    "output_csv_path = 'output.csv'  # Path to save the generated CSV\n",
    "\n",
    "# Read headers from the header file\n",
    "with open(header_file_path, 'r') as header_file:\n",
    "    headers = header_file.readline().strip().split('|')\n",
    "\n",
    "# Read the input file and write it to CSV format\n",
    "with open(input_file_path, 'r') as input_file, open(output_csv_path, 'w', newline='') as output_csv_file:\n",
    "    writer = csv.writer(output_csv_file)\n",
    "\n",
    "    # Write headers to the CSV\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Iterate through each row in the input file and write it to the CSV\n",
    "    for line in input_file:\n",
    "        row = line.strip().split('|')\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file has been generated and saved to {output_csv_path}\")\n",
    "\n",
    "\n",
    "import hl7\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to convert date to HL7 format\n",
    "def convert_datetime(dt_str):\n",
    "    try:\n",
    "        return datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S').strftime('%Y%m%d%H%M%S')\n",
    "    except Exception:\n",
    "        return dt_str\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'output.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Function to create an HL7-like message using python-hl7\n",
    "def create_hl7_message(row):\n",
    "    # MSH (Message Header) Segment\n",
    "    msh_segment = hl7.Segment()\n",
    "    msh_segment.append(\"MSH\")\n",
    "    msh_segment.append(\"|^~\\\\&\")\n",
    "    msh_segment.append(\"TouchWorks\")\n",
    "    msh_segment.append(\"Southwest Medical Associates\")\n",
    "    msh_segment.append(\"Rhapsody^Rhapsody\")\n",
    "    msh_segment.append(\"Epic^Epic\")\n",
    "    msh_segment.append(convert_datetime(row[\"PerformedDTTM\"]))  # Observation DateTime\n",
    "    msh_segment.append(\"\")  # Empty field for Message Control ID\n",
    "    msh_segment.append(\"ORU^R01\")  # Message Type\n",
    "    msh_segment.append(f'{row[\"Patient MRN\"]}_{row[\"ActivityHeaderID\"]}_{row[\"Result\"]}')  # Observation Unique ID\n",
    "    msh_segment.append(\"P\")  # Processing ID\n",
    "    msh_segment.append(\"2.5.1\")  # HL7 Version\n",
    "\n",
    "    # PID (Patient Identification) Segment\n",
    "    pid_segment = hl7.Segment()\n",
    "    pid_segment.append(\"PID\")\n",
    "    pid_segment.append(\"\")  # Set ID\n",
    "    pid_segment.append(\"\")  # Patient ID\n",
    "    pid_segment.append(f'{row[\"Patient MRN\"]}^^^^TWSMAMRN')  # Medical Record Number\n",
    "    pid_segment.append(f'{row[\"LastName\"]}^{row[\"FirstName\"]}^{row[\"MiddleName\"]}')  # Patient's Name\n",
    "    pid_segment.append(\"\")  # Mother's Maiden Name\n",
    "    pid_segment.append(f'{convert_datetime(row[\"DateOfBirth\"])}')  # Date of Birth\n",
    "    pid_segment.append(f'{row[\"Sex\"]}')  # Sex\n",
    "    pid_segment.append(\"\")  # Empty Race field\n",
    "    pid_segment.append(f'{row[\"APM_Patient_Street1\"]}^^{row[\"APM_Patient_City\"]}^{row[\"APM_Patient_State\"]}^{row[\"APM_Patient_Zip_Code\"]}^{row[\"APM_Patient_Country\"]}')  # Address\n",
    "\n",
    "    # OBR (Observation Request) Segment\n",
    "    obr_segment = hl7.Segment()\n",
    "    obr_segment.append(\"OBR\")\n",
    "    obr_segment.append(\"1\")  # Set ID\n",
    "    obr_segment.append(\"\")  # Empty fields for Order Numbers\n",
    "    obr_segment.append(\"\") \n",
    "    obr_segment.append(\"\") \n",
    "    obr_segment.append(\"\") \n",
    "    obr_segment.append(\"\") \n",
    "    obr_segment.append(convert_datetime(row[\"PerformedDTTM\"]))  # Observation DateTime\n",
    "\n",
    "    # OBX (Observation/Result) Segments\n",
    "    obx_segments = []\n",
    "    \n",
    "    # For each metric, we create an OBX segment\n",
    "    for idx, metric in enumerate([('PUL RATE', 'beats per minute', '8867-4'), ('BP DIAS', 'mm Hg', '8462-4'), \n",
    "                                  ('BP SYS', 'mm Hg', '8480-6'), ('WGT', 'lb', '3141-9'), \n",
    "                                  ('HGT', 'in', '8302-2'), ('O2', '', '59408-5'), ('TEMP', 'F', '8310-5')]):\n",
    "        obx_segment = hl7.Segment()\n",
    "        obx_segment.append(\"OBX\")\n",
    "        obx_segment.append(str(idx + 1))  # Set ID for each OBX\n",
    "        obx_segment.append(\"\")  # Empty Value Type\n",
    "        obx_segment.append(f'{metric[2]}^{metric[0]}^LN')  # LOINC Code and Metric Abbreviation\n",
    "        obx_segment.append(\"\")  # Observation Identifier\n",
    "        obx_segment.append(f'{row[\"Result\"]}')  # Observation Value\n",
    "        obx_segment.append(f'{metric[1]}')  # Unit of Measure\n",
    "        obx_segments.append(obx_segment)\n",
    "\n",
    "    # Combine all segments into an HL7 message\n",
    "    message = hl7.Message()\n",
    "    message.append(msh_segment)\n",
    "    message.append(pid_segment)\n",
    "    message.append(obr_segment)\n",
    "    for obx_segment in obx_segments:\n",
    "        message.append(obx_segment)\n",
    "\n",
    "    return message\n",
    "\n",
    "# Iterate over rows in the CSV and generate HL7 messages\n",
    "hl7_messages = []\n",
    "for _, row in df.iterrows():\n",
    "    hl7_message = create_hl7_message(row)\n",
    "    hl7_messages.append(str(hl7_message))\n",
    "\n",
    "# Save all generated HL7 messages into a text file\n",
    "with open('output_hl7.txt', 'w') as f:\n",
    "    for message in hl7_messages:\n",
    "        f.write(message + '\\n\\n')\n",
    "\n",
    "print(\"HL7 messages have been written to 'output_hl7.txt'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef570d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9eff0b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSH|^~\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|20241020222612||ORU^R01|20004200_420_20211022|P|2.5.1\n",
      "PID|||20004200^^^^TWSMAMRN||Martinez^David^E||20080419|M|||Martinez^^4479 E Mesquite Desert Trl^^Tucson\n",
      "OBR|1||||||20211022170300\n",
      "OBX|1||8867-4^PUL RATE^LN||68|bpm\n",
      "OBX|2||8480-6^BP SYS^LN||110|mm Hg\n",
      "OBX|3||8462-4^BP DIAS^LN||62|mm Hg\n",
      "OBX|4||8302-2^HGT^LN||156.21|in\n",
      "OBX|5||3141-9^WGT^LN||39.26|lb\n",
      "OBX|6||59408-5^O2^LN||97|\n",
      "OBX|7||8310-5^TEMP^LN||36.94|F\n",
      "OBX|8||8867-4^PUL RATE^LN||68|bpm\n",
      "OBX|9||8310-5^TEMP^LN||36.56|F\n",
      "OBX|10||8480-6^BP SYS^LN||114|mm Hg\n",
      "OBX|11||8462-4^BP DIAS^LN||68|mm Hg\n",
      "OBX|12||3141-9^WGT^LN||37.82|lb\n",
      "OBX|13||8302-2^HGT^LN||156.21|in\n",
      "OBX|14||59408-5^O2^LN||98|\n",
      "OBX|15||8302-2^HGT^LN||161.19|in\n",
      "OBX|16||3141-9^WGT^LN||40.82|lb\n",
      "OBX|17||8480-6^BP SYS^LN||110|mm Hg\n",
      "OBX|18||8462-4^BP DIAS^LN||60|mm Hg\n",
      "OBX|19||8310-5^TEMP^LN||37.11|F\n",
      "OBX|20||8867-4^PUL RATE^LN||73|bpm\n",
      "OBX|21||59408-5^O2^LN||98|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# HL7 Template Fields (MSH, PID, OBR, OBX)\n",
    "def generate_msh(segment_date, message_control_id):\n",
    "    return f\"MSH|^~\\\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|{segment_date}||ORU^R01|{message_control_id}|P|2.5.1\"\n",
    "\n",
    "def generate_pid(patient_id, last_name, first_name, middle_initial, dob, sex, address):\n",
    "    return f\"PID|||{patient_id}^^^^TWSMAMRN||{last_name}^{first_name}^{middle_initial}||{dob}|{sex}|||{address}\"\n",
    "\n",
    "def generate_obr(observation_time):\n",
    "    return f\"OBR|1||||||{observation_time}\"\n",
    "\n",
    "def generate_obx(index, loinc_code, description, result, unit):\n",
    "    return f\"OBX|{index}||{loinc_code}^{description}^LN||{result}|{unit}\"\n",
    "\n",
    "# Mapping of metric descriptions to LOINC codes and descriptions\n",
    "loinc_mapping = {\n",
    "    \"Heart Rate\": (\"8867-4\", \"PUL RATE\"),\n",
    "    \"Systolic\": (\"8480-6\", \"BP SYS\"),\n",
    "    \"Diastolic\": (\"8462-4\", \"BP DIAS\"),\n",
    "    \"Weight\": (\"3141-9\", \"WGT\"),\n",
    "    \"Height\": (\"8302-2\", \"HGT\"),\n",
    "    \"O2 Saturation\": (\"59408-5\", \"O2\"),\n",
    "    \"Temperature\": (\"8310-5\", \"TEMP\"),\n",
    "}\n",
    "\n",
    "# Adjusting the script based on the updated format and rules\n",
    "def create_hl7_from_csv_with_rules(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "        csv_reader = csv.reader(infile, delimiter='|')\n",
    "        current_patient = None\n",
    "        index = 1\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            # Extract relevant fields based on their positions in the row\n",
    "            patient_id = row[0]\n",
    "            visit_id = row[1]\n",
    "            last_name = row[2]\n",
    "            first_name = row[3]\n",
    "            middle_initial = row[4]\n",
    "            dob = row[5].replace(\"-\", \"\")\n",
    "            sex = row[6]\n",
    "            address = f\"{row[30]}^^{row[32]}^{row[33]}^{row[34]}\"\n",
    "            metric_desc = row[7]\n",
    "            result = row[9]\n",
    "            unit = row[19]\n",
    "            performed_dttm = row[12]\n",
    "            performed_dttm_short = performed_dttm.split(\" \")[0].replace(\"-\", \"\")\n",
    "            \n",
    "            # Create Message Control ID using VisitID_PatientID_PerformedDTTM\n",
    "            message_control_id = f\"{visit_id}_{patient_id}_{performed_dttm_short}\"\n",
    "            \n",
    "            # Check if we need to start a new patient message (PID segment)\n",
    "            if current_patient != patient_id:\n",
    "                if current_patient:  # if not the first patient, insert a newline for the next HL7 message\n",
    "                    outfile.write(\"\\n\\n\")\n",
    "                \n",
    "                # Write MSH segment\n",
    "                segment_date = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                msh = generate_msh(segment_date, message_control_id)\n",
    "                outfile.write(f\"{msh}\\n\")\n",
    "                \n",
    "                # Write PID segment\n",
    "                pid = generate_pid(visit_id, last_name, first_name, middle_initial, dob, sex, address)\n",
    "                outfile.write(f\"{pid}\\n\")\n",
    "                \n",
    "                # Write OBR segment\n",
    "                observation_time = performed_dttm.replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")\n",
    "                obr = generate_obr(observation_time[:14])\n",
    "                outfile.write(f\"{obr}\\n\")\n",
    "                \n",
    "                # Reset the OBX index\n",
    "                index = 1\n",
    "                \n",
    "                current_patient = patient_id\n",
    "            \n",
    "            # Map the metric description to the correct LOINC code and description\n",
    "            loinc_lab_code, loinc_desc = loinc_mapping.get(metric_desc, (None, None))\n",
    "            if loinc_lab_code:\n",
    "                # Write OBX segment for each metric\n",
    "                obx = generate_obx(index, loinc_lab_code, loinc_desc, result, unit)\n",
    "                outfile.write(f\"{obx}\\n\")\n",
    "                index += 1\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = 'Input.txt'  # Replace with the actual path to the input file\n",
    "output_file_path = 'output_hl7_with_rules.txt'\n",
    "\n",
    "# Run the updated HL7 generation process\n",
    "create_hl7_from_csv_with_rules(input_file_path, output_file_path)\n",
    "\n",
    "# Load the generated output to check the results\n",
    "with open(output_file_path, 'r') as file:\n",
    "    hl7_output_rules = file.read()\n",
    "\n",
    "# Display the first 2000 characters of the generated HL7 output for validation\n",
    "print(hl7_output_rules[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0534008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSH|^~\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|20241020232259||ORU^R01|20004200_420_20211022|P|2.5.1\n",
      "PID|||420^^^^TWSMAMRN||Martinez^David^E||20080419|M|||Martinez^^4479 E Mesquite Desert Trl^^Tucson\n",
      "OBR|1||||||20211022170300\n",
      "OBX|1||8867-4^PUL RATE^LN||68|bpm\n",
      "OBX|2||8480-6^BP SYS^LN||110|mm Hg\n",
      "OBX|3||8462-4^BP DIAS^LN||62|mm Hg\n",
      "OBX|4||8302-2^HGT^LN||156.21|in\n",
      "OBX|5||3141-9^WGT^LN||39.26|lb\n",
      "OBX|6||59408-5^O2^LN||97|\n",
      "OBX|7||8310-5^TEMP^LN||36.94|F\n",
      "\n",
      "\n",
      "MSH|^~\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|20241020232259||ORU^R01|20004200_420_20211110|P|2.5.1\n",
      "PID|||420^^^^TWSMAMRN||Martinez^David^E||20080419|M|||Martinez^^4479 E Mesquite Desert Trl^^Tucson\n",
      "OBR|1||||||20211110131100\n",
      "OBX|1||8867-4^PUL RATE^LN||68|bpm\n",
      "OBX|2||8310-5^TEMP^LN||36.56|F\n",
      "OBX|3||8480-6^BP SYS^LN||114|mm Hg\n",
      "OBX|4||8462-4^BP DIAS^LN||68|mm Hg\n",
      "OBX|5||3141-9^WGT^LN||37.82|lb\n",
      "OBX|6||8302-2^HGT^LN||156.21|in\n",
      "OBX|7||59408-5^O2^LN||98|\n",
      "\n",
      "\n",
      "MSH|^~\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|20241020232259||ORU^R01|20004200_420_20221128|P|2.5.1\n",
      "PID|||420^^^^TWSMAMRN||Martinez^David^E||20080419|M|||Martinez^^4479 E Mesquite Desert Trl^^Tucson\n",
      "OBR|1||||||20221128125800\n",
      "OBX|1||8302-2^HGT^LN||161.19|in\n",
      "OBX|2||3141-9^WGT^LN||40.82|lb\n",
      "OBX|3||8480-6^BP SYS^LN||110|mm Hg\n",
      "OBX|4||8462-4^BP DIAS^LN||60|mm Hg\n",
      "OBX|5||8310-5^TEMP^LN||37.11|F\n",
      "OBX|6||8867-4^PUL RATE^LN||73|bpm\n",
      "OBX|7||59408-5^O2^LN||98|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# HL7 Template Fields (MSH, PID, OBR, OBX)\n",
    "def generate_msh(segment_date, message_control_id):\n",
    "    return f\"MSH|^~\\\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|{segment_date}||ORU^R01|{message_control_id}|P|2.5.1\"\n",
    "\n",
    "def generate_pid(patient_id, last_name, first_name, middle_initial, dob, sex, address):\n",
    "    return f\"PID|||{patient_id}^^^^TWSMAMRN||{last_name}^{first_name}^{middle_initial}||{dob}|{sex}|||{address}\"\n",
    "\n",
    "def generate_obr(observation_time):\n",
    "    return f\"OBR|1||||||{observation_time}\"\n",
    "\n",
    "def generate_obx(index, loinc_code, description, result, unit):\n",
    "    return f\"OBX|{index}||{loinc_code}^{description}^LN||{result}|{unit}\"\n",
    "\n",
    "# Mapping of metric descriptions to LOINC codes and descriptions\n",
    "loinc_mapping = {\n",
    "    \"Heart Rate\": (\"8867-4\", \"PUL RATE\"),\n",
    "    \"Systolic\": (\"8480-6\", \"BP SYS\"),\n",
    "    \"Diastolic\": (\"8462-4\", \"BP DIAS\"),\n",
    "    \"Weight\": (\"3141-9\", \"WGT\"),\n",
    "    \"Height\": (\"8302-2\", \"HGT\"),\n",
    "    \"O2 Saturation\": (\"59408-5\", \"O2\"),\n",
    "    \"Temperature\": (\"8310-5\", \"TEMP\"),\n",
    "}\n",
    "\n",
    "# Adjusting the script based on the updated format and rules\n",
    "def create_hl7_from_csv_with_rules(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "        csv_reader = csv.reader(infile, delimiter='|')\n",
    "        current_patient = None\n",
    "        current_performed_dttm = None\n",
    "        index = 1\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            # Extract relevant fields based on their positions in the row\n",
    "            patient_id = row[0]\n",
    "            visit_id = row[1]\n",
    "            last_name = row[2]\n",
    "            first_name = row[3]\n",
    "            middle_initial = row[4]\n",
    "            dob = row[5].replace(\"-\", \"\")\n",
    "            sex = row[6]\n",
    "            address = f\"{row[30]}^^{row[32]}^{row[33]}^{row[34]}\"\n",
    "            metric_desc = row[7]\n",
    "            result = row[9]\n",
    "            unit = row[19]\n",
    "            performed_dttm = row[12]\n",
    "            observation_time = performed_dttm.replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")\n",
    "            performed_dttm_short = performed_dttm.split(\" \")[0].replace(\"-\", \"\")\n",
    "            \n",
    "            # Create Message Control ID using VisitID_PatientID_PerformedDTTM\n",
    "            message_control_id = f\"{visit_id}_{patient_id}_{performed_dttm_short}\"\n",
    "            \n",
    "            # Check if we need to start a new encounter\n",
    "            if current_performed_dttm != performed_dttm:\n",
    "                if current_performed_dttm:  # Close the previous message with a newline\n",
    "                    outfile.write(\"\\n\\n\")\n",
    "                \n",
    "                # Write MSH segment\n",
    "                segment_date = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                msh = generate_msh(segment_date, message_control_id)\n",
    "                outfile.write(f\"{msh}\\n\")\n",
    "                \n",
    "                # Write PID segment\n",
    "                pid = generate_pid(patient_id, last_name, first_name, middle_initial, dob, sex, address)\n",
    "                outfile.write(f\"{pid}\\n\")\n",
    "                \n",
    "                # Write OBR segment\n",
    "                obr = generate_obr(observation_time[:14])\n",
    "                outfile.write(f\"{obr}\\n\")\n",
    "                \n",
    "                # Reset OBX index and update current_performed_dttm\n",
    "                index = 1\n",
    "                current_performed_dttm = performed_dttm\n",
    "            \n",
    "            # Map the metric description to the correct LOINC code and description\n",
    "            loinc_lab_code, loinc_desc = loinc_mapping.get(metric_desc, (None, None))\n",
    "            if loinc_lab_code:\n",
    "                # Write OBX segment for each metric\n",
    "                obx = generate_obx(index, loinc_lab_code, loinc_desc, result, unit)\n",
    "                outfile.write(f\"{obx}\\n\")\n",
    "                index += 1\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = 'Input.txt'  # Replace with the actual path to the input file\n",
    "output_file_path = 'output_hl7_with_rules.txt'\n",
    "\n",
    "# Run the updated HL7 generation process\n",
    "create_hl7_from_csv_with_rules(input_file_path, output_file_path)\n",
    "\n",
    "# Load the generated output to check the results\n",
    "with open(output_file_path, 'r') as file:\n",
    "    hl7_output_rules = file.read()\n",
    "\n",
    "# Display the first 2000 characters of the generated HL7 output for validation\n",
    "print(hl7_output_rules[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d843bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41dc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f147fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f80df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bf53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
