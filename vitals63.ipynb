{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca87711d-b17c-4fdf-8662-d72449c81ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "<>:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "/var/folders/pc/6rmkz3b536l1k66dbrhqbl2r0000gn/T/ipykernel_33095/3605166121.py:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n",
      "/var/folders/pc/6rmkz3b536l1k66dbrhqbl2r0000gn/T/ipykernel_33095/3605166121.py:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Read the Input File and convert to pandas dataframe\u001b[39;00m\n\u001b[1;32m     14\u001b[0m input_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPIC/Input.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df_input \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43minput_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mheader)\n\u001b[1;32m     16\u001b[0m df_input\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "# Defining the input file header\n",
    "\n",
    "header=['PatientID', 'PatientMRN', 'LastName', 'FirstName', 'MiddleName', 'DateofBirth', 'Sex', 'Metric_Desc', 'Metric_Abbr', 'Result', 'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue', 'QOCClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue', 'NumericFinding', 'Unit_Abbr', 'RecordedDTTM', 'QODE', 'Vital_Status', 'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode', 'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name', 'APM_Patient_Last_Name', 'APM_Patient_MI', 'APM_Patient_Street1', 'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State', 'APM_Patient_Zip_Code', 'APM_Patient_Country', 'APM_Patient_Sex', 'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone', 'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type', 'Patient_Primary_Phone_Number', 'Patient_Email']\n",
    "# Read the Input File and convert to pandas dataframe\n",
    "input_files = glob.glob('EPIC/Input.txt')\n",
    "df_input = pd.read_csv(input_files[0], delimiter='|', header=None, names=header)\n",
    "df_input.fillna('', inplace=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the Input File and convert to pandas dataframe\n",
    "\n",
    "input_files = glob.glob('EPIC/Vitals_allscript.csv')\n",
    "Vitals_allscript_df = pd.read_csv(input_files[0], delimiter=',',)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Vitals_allscript_df.head(5)\n",
    "# df_input.columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Apply strptime to each element of the 'CreateDTTM' column\n",
    "df_input['reformated_CreateDTTM'] = pd.to_datetime(df_input['CreateDTTM'], format='%Y-%m-%d %H:%M:%S.%f').dt.strftime('%m-%d-%Y %H:%M')\n",
    "\n",
    "# Convert 'reformated_CreateDTTM' back to datetime objects\n",
    "df_input['reformated_CreateDTTM'] = pd.to_datetime(df_input['reformated_CreateDTTM'], format='%m-%d-%Y %H:%M')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_input.head()\n",
    "df_input['DateOfBirth'] = df_input['DateofBirth'].str.replace('-', '', regex=False)\n",
    "df_input['CreateDTTM_converted'] = df_input['CreateDTTM'].str.replace('-', '', regex=False).str.replace(' ', '', regex=False).str.replace(':', '', regex=False).str.replace('.', '', regex=False).str[:-3]\n",
    "\n",
    "\n",
    "\n",
    "lookup_table = {\n",
    "\n",
    "    #MSH Segment\n",
    "    \"MSH-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-3\": {\"Source Column\": None, \"Default Value\": \"TouchWorks\"},\n",
    "    \"MSH-4\": {\"Source Column\": None, \"Default Value\": \"MountainWest\"},\n",
    "    \"MSH-5\": {\"Source Column\": None, \"Default Value\": \"Rhapsody^Rhapsody\"},\n",
    "    \"MSH-6\": {\"Source Column\": None, \"Default Value\": \"Epic^Epic\"},\n",
    "    \"MSH-7\": {\"Source Column\": None, \"Default Value\": datetime.now().strftime(\"%Y%m%d%H%M%S\")},\n",
    "    \"MSH-8\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-9\": {\"Source Column\": None, \"Default Value\": \"ORU^R01\"},\n",
    "    \"MSH-10\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-11\": {\"Source Column\": None, \"Default Value\": \"P\"},\n",
    "    \"MSH-12\": {\"Source Column\": None, \"Default Value\": \"2.5.1\"},\n",
    "\n",
    "\n",
    "\n",
    "    #PID segment\n",
    "\n",
    "    \"PID-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.1\": {\"Source Column\": \"PatientMRN\", \"Default Value\": None},\n",
    "    \"PID-3.2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.3\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.5\": {\"Source Column\": None, \"Default Value\": \"TWSMAMRN\"},\n",
    "    \"PID-4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-5.1\": {\"Source Column\": \"LastName\", \"Default Value\": None},\n",
    "    \"PID-5.2\": {\"Source Column\": \"FirstName\", \"Default Value\": None},\n",
    "    \"PID-5.3\": {\"Source Column\": \"MiddleName\", \"Default Value\": None},\n",
    "    \"PID-6\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-7\": {\"Source Column\": \"DateOfBirth\", \"Default Value\": None},\n",
    "    \"PID-8\": {\"Source Column\": \"Sex\", \"Default Value\": None},\n",
    "    \"PID-9\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-10\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-11\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-12\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-13\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-14\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-15\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-16\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-17\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-18\": {\"Source Column\": None, \"Default Value\": None},\n",
    "\n",
    "\n",
    "    #OBR segment\n",
    "\n",
    "    \"OBR-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-3\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-5\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-6\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-7\": {\"Source Column\": \"RecordedDTTM\", \"Default Value\": None},\n",
    "\n",
    "\n",
    "    #OBX segment\n",
    "\n",
    "    \"OBX-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-3\": {\"Source Column\": \"Metric_Abbr\", \"Default Value\": None},\n",
    "    \"OBX-4\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-5\": {\"Source Column\": \"Result\", \"Default Value\": None},\n",
    "    \"OBX-6\": {\"Source Column\": \"Unit_Abbr\", \"Default Value\": None},\n",
    "    \"OBX-7\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-8\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-9\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-10\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-11\": {\"Source Column\":None, \"Default Value\": None},\n",
    "    \"OBX-12\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-13\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-14\":{\"Source Column\":\"?\",\"Default Value\":None}\n",
    "}\n",
    "\n",
    "def convert_to_int(value):\n",
    "\n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except (ValueError, TypeError):\n",
    "        return value\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "def get_value(field, row):\n",
    "\n",
    "      source_column = lookup_table[field][\"Source Column\"]\n",
    "      default_value = lookup_table[field][\"Default Value\"]\n",
    "\n",
    "      if source_column:\n",
    "          if isinstance(source_column, list):\n",
    "              return \"_\".join([str(row.get(col, '')) for col in source_column])\n",
    "          return row.get(source_column, default_value)\n",
    "      return default_value\n",
    "\n",
    "def parse_to_hl7(df_input, lookup_table):\n",
    "\n",
    "    hl7_lines = []\n",
    "    obx_counter = {}\n",
    "    obr_counter = {}\n",
    "    empty_list = []\n",
    "    count = 0\n",
    "\n",
    "    for index, row in df_input.iterrows():\n",
    "\n",
    "      PatientMRN= row['PatientMRN']\n",
    "      if PatientMRN not in obr_counter:\n",
    "            obr_counter[PatientMRN] = 1\n",
    "      else:\n",
    "            obr_counter[PatientMRN] += 1\n",
    "\n",
    "      #Create MSH segment\n",
    "\n",
    "      msh_segment = [\n",
    "          f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n",
    "\n",
    "              ]\n",
    "\n",
    "      # Create PID segment\n",
    "      pid_segment = [\n",
    "                  f\"PID|||{get_value('PID-3.1', row)}^^^^{get_value('PID-3.5', row)}||{get_value('PID-5.1', row)}^{get_value('PID-5.2', row)}||{get_value('PID-7', row)}|{get_value('PID-8', row)}\"\n",
    "\n",
    "                  ]\n",
    "      # Create OBR segment\n",
    "      obr_segment = [\n",
    "\n",
    "                  f\"OBR|{obr_counter[PatientMRN]}||||||{get_value('OBR-3', row)}|||||||||{convert_to_int(get_value('OBR-7', row))}\"\n",
    "\n",
    "              ]\n",
    "        \n",
    "      obx_segment = [\n",
    "            f\"OBX|{obx_counter[RecordedDTTM]}||{row_get('LoincLabCode', row)}^{row_get('Metric_Abbr', row)}^LN||{row_get('Result', row)}|{row_get('Unit_Abbr', row)}\"\n",
    "        ]\n",
    "\n",
    "      hl7_message = \"\\n\".join(msh_segment + pid_segment + obr_segment + obx_segment)\n",
    "\n",
    "      hl7_lines.append(hl7_message)\n",
    "\n",
    "    return hl7_lines\n",
    "# Parse the input DataFrame to HL7 formatted output\n",
    "\n",
    "hl7_output = parse_to_hl7(df_input, lookup_table)\n",
    "# hl7_output\n",
    "\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    sanitized = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
    "    sanitized = sanitized.replace(' ', '_')\n",
    "    return sanitized\n",
    "\n",
    "\n",
    "def remove_duplicate_segments(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    unique_segments = {'MSH': False, 'PID': False, 'ORC': False, 'OBR': False}\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            segment_type = line.split('|')[0]\n",
    "            if segment_type in unique_segments:\n",
    "                if not unique_segments[segment_type]:\n",
    "                    file.write(line)\n",
    "                    unique_segments[segment_type] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "for index, row in df_input.iterrows():\n",
    "    filename = f\"{row['PatientMRN']}\"\n",
    "    sanitized_filename = sanitize_filename(filename)\n",
    "    file_path = f\"EPIC/{sanitized_filename}.hl7\"\n",
    "    file_paths.append(file_path)\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in hl7_output:\n",
    "                file.write(line + \"\\n\")\n",
    "\n",
    "for file_path in set(file_paths):\n",
    "    remove_duplicate_segments(file_path)\n",
    "\n",
    "\n",
    "\n",
    "print(hl7_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96edc0-45ab-4aea-b781-137cdd3507b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b055810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been generated and saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Paths for input and output files\n",
    "header_file_path = 'header.txt'  # Path to header.txt\n",
    "input_file_path = 'Input.txt'  # Path to Input.txt\n",
    "output_csv_path = 'output.csv'  # Path to save the generated CSV\n",
    "\n",
    "# Read headers from the header file\n",
    "with open(header_file_path, 'r') as header_file:\n",
    "    headers = header_file.readline().strip().split('|')\n",
    "\n",
    "# Read the input file and write it to CSV format\n",
    "with open(input_file_path, 'r') as input_file, open(output_csv_path, 'w', newline='') as output_csv_file:\n",
    "    writer = csv.writer(output_csv_file)\n",
    "\n",
    "    # Write headers to the CSV\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Iterate through each row in the input file and write it to the CSV\n",
    "    for line in input_file:\n",
    "        row = line.strip().split('|')\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file has been generated and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aefee1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Source Column/Field name', 'Source Example', 'Description', 'Format',\n",
      "       'HL7 field', 'Required/Highly recommended/Nice to have/',\n",
      "       'Default/Generic value', 'HL7 example', 'Notes', 'Follow up'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the vitals csv\n",
    "vitals_csv_path = 'Vitals_allscript.csv'  # Update with your actual file path\n",
    "vitals_df = pd.read_csv(vitals_csv_path)\n",
    "\n",
    "# Print column names to inspect them\n",
    "print(vitals_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472d47f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output CSV Columns: Index(['PatientId', 'Patient MRN', 'LastName', 'FirstName', 'MiddleName',\n",
      "       'DateOfBirth', 'Sex', 'Metric_Desc', 'Metric_Abbr', 'Result',\n",
      "       'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue',\n",
      "       'QOClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue',\n",
      "       'NumericFinding', 'Unit_Abbr', 'RecordedDTTM', 'QODE', 'Vital_Status',\n",
      "       'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode',\n",
      "       'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name',\n",
      "       'APM_Patient_Last_Name', 'APM_Patient_MI', 'APM_Patient_Street1',\n",
      "       'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State',\n",
      "       'APM_Patient_Zip_Code', 'APM_Patient_Country', 'APM_Patient_Sex',\n",
      "       'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone',\n",
      "       'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type',\n",
      "       'Patient_Primary_Phone_Number', 'Patient_Emailx'],\n",
      "      dtype='object')\n",
      "Vitals Description CSV Columns: Index(['Source Column/Field name', 'Source Example', 'Description', 'Format',\n",
      "       'HL7 field', 'Required/Highly recommended/Nice to have/',\n",
      "       'Default/Generic value', 'HL7 example', 'Notes', 'Follow up'],\n",
      "      dtype='object')\n",
      "KeyError: 'F'. Skipping this metric.\n",
      "KeyError: 'F'. Skipping this metric.\n",
      "KeyError: 'F'. Skipping this metric.\n",
      "HL7-like messages have been written to 'output.hl7.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the CSV files\n",
    "output_csv_path = 'output.csv'  # Path to your output CSV\n",
    "vitals_csv_path = 'Vitals_allscript.csv'  # Path to your vitals description CSV\n",
    "\n",
    "# Read the CSV files\n",
    "output_df = pd.read_csv(output_csv_path)\n",
    "vitals_df = pd.read_csv(vitals_csv_path)\n",
    "\n",
    "# Print column names to ensure correct access\n",
    "print(\"Output CSV Columns:\", output_df.columns)\n",
    "print(\"Vitals Description CSV Columns:\", vitals_df.columns)\n",
    "\n",
    "# Convert datetime to HL7 format (YYYYMMDDHHMMSS)\n",
    "def convert_datetime(dt_str):\n",
    "    try:\n",
    "        return datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S.%f').strftime('%Y%m%d%H%M%S')\n",
    "    except:\n",
    "        return dt_str\n",
    "\n",
    "# Function to create HL7-like text from data\n",
    "def create_hl7_message(output_row, vitals_df):\n",
    "    hl7_message = []\n",
    "    \n",
    "    # Create MSH (Message Header) Segment\n",
    "    msh_segment = f'MSH|^~\\\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|{convert_datetime(output_row[\"CreateDTTM\"])}||ORU^R01|{output_row[\"PatientId\"]}_{output_row[\"ActivityHeaderID\"]}_{convert_datetime(output_row[\"PerformedDTTM\"])}|P|2.5.1'\n",
    "    hl7_message.append(msh_segment)\n",
    "    \n",
    "    # Create PID (Patient Identification) Segment\n",
    "    pid_segment = f'PID|||{output_row[\"Patient MRN\"]}^^^^TWSMAMRN||{output_row[\"LastName\"]}^{output_row[\"FirstName\"]}^{output_row[\"MiddleName\"]}||{output_row[\"DateOfBirth\"].replace(\"-\", \"\")}|{output_row[\"Sex\"]}|||{output_row[\"APM_Patient_Street1\"]}^^{output_row[\"APM_Patient_City\"]}^{output_row[\"APM_Patient_State\"]}^{output_row[\"APM_Patient_Zip_Code\"]}'\n",
    "    hl7_message.append(pid_segment)\n",
    "    \n",
    "    # Create OBR (Observation Request) Segment\n",
    "    obr_segment = f'OBR|1||||||{convert_datetime(output_row[\"PerformedDTTM\"])}'\n",
    "    hl7_message.append(obr_segment)\n",
    "    \n",
    "    # Create OBX (Observation Result) Segments\n",
    "    obx_counter = 1\n",
    "    for _, vital_row in vitals_df.iterrows():\n",
    "        # Matching the Source Example or HL7 Field to the relevant field in output.csv\n",
    "        metric = vital_row['Source Example']\n",
    "        if metric in output_row.values:  # Check if the metric exists in the output row\n",
    "            try:\n",
    "                obx_segment = f'OBX|{obx_counter}||{vital_row[\"HL7 example\"]}^LN||{output_row[metric]}|{vital_row[\"Description\"]}'\n",
    "                hl7_message.append(obx_segment)\n",
    "                obx_counter += 1\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: {e}. Skipping this metric.\")\n",
    "    \n",
    "    # Return the combined HL7 message as a string\n",
    "    return '\\n'.join(hl7_message)\n",
    "\n",
    "# Iterate through each row in the output CSV to create HL7 messages\n",
    "hl7_messages = []\n",
    "for _, row in output_df.iterrows():\n",
    "    hl7_message = create_hl7_message(row, vitals_df)\n",
    "    hl7_messages.append(hl7_message)\n",
    "\n",
    "# Write HL7-like messages to a text file\n",
    "with open('output.hl7.txt', 'w') as f:\n",
    "    for message in hl7_messages:\n",
    "        f.write(message + '\\n\\n')  # Separate each message with a double newline\n",
    "\n",
    "# Display completion message\n",
    "print(\"HL7-like messages have been written to 'output.hl7.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359f21b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatientId', 'Patient MRN', 'LastName', 'FirstName', 'MiddleName',\n",
      "       'DateOfBirth', 'Sex', 'Metric_Desc', 'Metric_Abbr', 'Result',\n",
      "       'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue',\n",
      "       'QOClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue',\n",
      "       'NumericFinding', 'Unit_Abbr', 'RecordedDTTM', 'QODE', 'Vital_Status',\n",
      "       'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode',\n",
      "       'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name',\n",
      "       'APM_Patient_Last_Name', 'APM_Patient_MI', 'APM_Patient_Street1',\n",
      "       'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State',\n",
      "       'APM_Patient_Zip_Code', 'APM_Patient_Country', 'APM_Patient_Sex',\n",
      "       'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone',\n",
      "       'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type',\n",
      "       'Patient_Primary_Phone_Number', 'Patient_Emailx'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'output.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Print the column names to verify\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53274ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HL7 messages have been written to 'output_hl7.txt'.\n"
     ]
    }
   ],
   "source": [
    "import hl7\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to convert date to HL7 format\n",
    "def convert_datetime(dt_str):\n",
    "    try:\n",
    "        return datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S').strftime('%Y%m%d%H%M%S')\n",
    "    except Exception:\n",
    "        return dt_str\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'output.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Function to create an HL7-like message using python-hl7\n",
    "def create_hl7_message(row):\n",
    "    # MSH (Message Header) Segment\n",
    "    msh_segment = hl7.Segment()\n",
    "    msh_segment.append(\"MSH\")\n",
    "    msh_segment.append(\"^~\\\\&\")\n",
    "    msh_segment.append(\"TouchWorks\")\n",
    "    msh_segment.append(\"Southwest Medical Associates\")\n",
    "    msh_segment.append(\"Rhapsody^Rhapsody\")\n",
    "    msh_segment.append(\"Epic^Epic\")\n",
    "    msh_segment.append(convert_datetime(row[\"PerformedDTTM\"]))  # Convert date to HL7 format\n",
    "    msh_segment.append(\"\")\n",
    "    msh_segment.append(\"ORU^R01\")\n",
    "    msh_segment.append(f'{row[\"Patient MRN\"]}_{row[\"ActivityHeaderID\"]}_{row[\"Result\"]}')  # Patient MRN, ActivityHeaderID, and Result\n",
    "    msh_segment.append(\"P\")\n",
    "    msh_segment.append(\"2.5.1\")\n",
    "    \n",
    "    # PID (Patient Identification) Segment\n",
    "    pid_segment = hl7.Segment()\n",
    "    pid_segment.append(\"PID\")\n",
    "    pid_segment.append(\"\")\n",
    "    pid_segment.append(\"\")\n",
    "    pid_segment.append(f'{row[\"LastName\"]}^^^^TWSMAMRN')  # Last name and Medical Record Number\n",
    "    pid_segment.append(f'{row[\"FirstName\"]}^{row[\"MiddleName\"]}^{row[\"DateOfBirth\"]}')  # First name, Middle name, and Date of Birth\n",
    "    pid_segment.append(\"\")\n",
    "    pid_segment.append(f'{row[\"Sex\"]}|{row[\"Metric_Desc\"]}')  # Sex and Metric Description\n",
    "    pid_segment.append(\"\")\n",
    "    pid_segment.append(f'{row[\"APM_Patient_Street1\"]}^^{row[\"APM_Patient_City\"]}^{row[\"APM_Patient_State\"]}^{row[\"APM_Patient_Zip_Code\"]}^{row[\"APM_Patient_Country\"]}')  # Address\n",
    "    \n",
    "    # OBR (Observation Request) Segment\n",
    "    obr_segment = hl7.Segment()\n",
    "    obr_segment.append(\"OBR\")\n",
    "    obr_segment.append(\"1\")\n",
    "    obr_segment.append(\"\")\n",
    "    obr_segment.append(\"\")\n",
    "    obr_segment.append(\"\")\n",
    "    obr_segment.append(\"\")\n",
    "    obr_segment.append(\"\")\n",
    "    obr_segment.append(f'{row[\"Result\"]}')  # Observation Result\n",
    "    \n",
    "    # OBX (Observation/Result) Segment\n",
    "    obx_segment = hl7.Segment()\n",
    "    obx_segment.append(\"OBX\")\n",
    "    obx_segment.append(\"1\")\n",
    "    obx_segment.append(\"\")\n",
    "    obx_segment.append(f'{row[\"LoincLabCode\"]}^{row[\"Metric_Abbr\"]}^LN')  # LOINC Code and Metric Abbreviation\n",
    "    obx_segment.append(\"\")\n",
    "    obx_segment.append(f'{row[\"Result\"]}')  # Result Value\n",
    "    obx_segment.append(f'{row[\"UnitOfMeasure\"]}')  # Unit of Measure\n",
    "    \n",
    "    # Combine segments into a single HL7 message\n",
    "    message = hl7.Message()\n",
    "    message.append(msh_segment)\n",
    "    message.append(pid_segment)\n",
    "    message.append(obr_segment)\n",
    "    message.append(obx_segment)\n",
    "    \n",
    "    return message\n",
    "\n",
    "# Create HL7 messages from the CSV data\n",
    "hl7_messages = []\n",
    "for _, row in df.iterrows():\n",
    "    hl7_message = create_hl7_message(row)\n",
    "    hl7_messages.append(str(hl7_message))\n",
    "\n",
    "# Save the HL7-like messages to a text file\n",
    "with open('output_hl7.txt', 'w') as f:\n",
    "    for message in hl7_messages:\n",
    "        f.write(message + '\\n\\n')\n",
    "\n",
    "print(\"HL7 messages have been written to 'output_hl7.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0342be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774e10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
