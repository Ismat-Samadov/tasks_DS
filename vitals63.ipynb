{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca87711d-b17c-4fdf-8662-d72449c81ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "<>:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "/var/folders/pc/6rmkz3b536l1k66dbrhqbl2r0000gn/T/ipykernel_33095/3605166121.py:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n",
      "/var/folders/pc/6rmkz3b536l1k66dbrhqbl2r0000gn/T/ipykernel_33095/3605166121.py:161: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Read the Input File and convert to pandas dataframe\u001b[39;00m\n\u001b[1;32m     14\u001b[0m input_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPIC/Input.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df_input \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43minput_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mheader)\n\u001b[1;32m     16\u001b[0m df_input\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "# Defining the input file header\n",
    "\n",
    "header=['PatientID', 'PatientMRN', 'LastName', 'FirstName', 'MiddleName', 'DateofBirth', 'Sex', 'Metric_Desc', 'Metric_Abbr', 'Result', 'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue', 'QOCClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue', 'NumericFinding', 'Unit_Abbr', 'RecordedDTTM', 'QODE', 'Vital_Status', 'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode', 'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name', 'APM_Patient_Last_Name', 'APM_Patient_MI', 'APM_Patient_Street1', 'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State', 'APM_Patient_Zip_Code', 'APM_Patient_Country', 'APM_Patient_Sex', 'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone', 'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type', 'Patient_Primary_Phone_Number', 'Patient_Email']\n",
    "# Read the Input File and convert to pandas dataframe\n",
    "input_files = glob.glob('EPIC/Input.txt')\n",
    "df_input = pd.read_csv(input_files[0], delimiter='|', header=None, names=header)\n",
    "df_input.fillna('', inplace=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the Input File and convert to pandas dataframe\n",
    "\n",
    "input_files = glob.glob('EPIC/Vitals_allscript.csv')\n",
    "Vitals_allscript_df = pd.read_csv(input_files[0], delimiter=',',)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Vitals_allscript_df.head(5)\n",
    "# df_input.columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Apply strptime to each element of the 'CreateDTTM' column\n",
    "df_input['reformated_CreateDTTM'] = pd.to_datetime(df_input['CreateDTTM'], format='%Y-%m-%d %H:%M:%S.%f').dt.strftime('%m-%d-%Y %H:%M')\n",
    "\n",
    "# Convert 'reformated_CreateDTTM' back to datetime objects\n",
    "df_input['reformated_CreateDTTM'] = pd.to_datetime(df_input['reformated_CreateDTTM'], format='%m-%d-%Y %H:%M')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_input.head()\n",
    "df_input['DateOfBirth'] = df_input['DateofBirth'].str.replace('-', '', regex=False)\n",
    "df_input['CreateDTTM_converted'] = df_input['CreateDTTM'].str.replace('-', '', regex=False).str.replace(' ', '', regex=False).str.replace(':', '', regex=False).str.replace('.', '', regex=False).str[:-3]\n",
    "\n",
    "\n",
    "\n",
    "lookup_table = {\n",
    "\n",
    "    #MSH Segment\n",
    "    \"MSH-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-3\": {\"Source Column\": None, \"Default Value\": \"TouchWorks\"},\n",
    "    \"MSH-4\": {\"Source Column\": None, \"Default Value\": \"MountainWest\"},\n",
    "    \"MSH-5\": {\"Source Column\": None, \"Default Value\": \"Rhapsody^Rhapsody\"},\n",
    "    \"MSH-6\": {\"Source Column\": None, \"Default Value\": \"Epic^Epic\"},\n",
    "    \"MSH-7\": {\"Source Column\": None, \"Default Value\": datetime.now().strftime(\"%Y%m%d%H%M%S\")},\n",
    "    \"MSH-8\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-9\": {\"Source Column\": None, \"Default Value\": \"ORU^R01\"},\n",
    "    \"MSH-10\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"MSH-11\": {\"Source Column\": None, \"Default Value\": \"P\"},\n",
    "    \"MSH-12\": {\"Source Column\": None, \"Default Value\": \"2.5.1\"},\n",
    "\n",
    "\n",
    "\n",
    "    #PID segment\n",
    "\n",
    "    \"PID-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.1\": {\"Source Column\": \"PatientMRN\", \"Default Value\": None},\n",
    "    \"PID-3.2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.3\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-3.5\": {\"Source Column\": None, \"Default Value\": \"TWSMAMRN\"},\n",
    "    \"PID-4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-5.1\": {\"Source Column\": \"LastName\", \"Default Value\": None},\n",
    "    \"PID-5.2\": {\"Source Column\": \"FirstName\", \"Default Value\": None},\n",
    "    \"PID-5.3\": {\"Source Column\": \"MiddleName\", \"Default Value\": None},\n",
    "    \"PID-6\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-7\": {\"Source Column\": \"DateOfBirth\", \"Default Value\": None},\n",
    "    \"PID-8\": {\"Source Column\": \"Sex\", \"Default Value\": None},\n",
    "    \"PID-9\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-10\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-11\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-12\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-13\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-14\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-15\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-16\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-17\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"PID-18\": {\"Source Column\": None, \"Default Value\": None},\n",
    "\n",
    "\n",
    "    #OBR segment\n",
    "\n",
    "    \"OBR-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-3\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-4\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-5\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-6\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBR-7\": {\"Source Column\": \"RecordedDTTM\", \"Default Value\": None},\n",
    "\n",
    "\n",
    "    #OBX segment\n",
    "\n",
    "    \"OBX-1\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-2\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-3\": {\"Source Column\": \"Metric_Abbr\", \"Default Value\": None},\n",
    "    \"OBX-4\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-5\": {\"Source Column\": \"Result\", \"Default Value\": None},\n",
    "    \"OBX-6\": {\"Source Column\": \"Unit_Abbr\", \"Default Value\": None},\n",
    "    \"OBX-7\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-8\": {\"Source Column\": None, \"Default Value\": None},\n",
    "    \"OBX-9\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-10\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-11\": {\"Source Column\":None, \"Default Value\": None},\n",
    "    \"OBX-12\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-13\":{\"Source Column\":None,\"Default Value\":None},\n",
    "    \"OBX-14\":{\"Source Column\":\"?\",\"Default Value\":None}\n",
    "}\n",
    "\n",
    "def convert_to_int(value):\n",
    "\n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except (ValueError, TypeError):\n",
    "        return value\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "def get_value(field, row):\n",
    "\n",
    "      source_column = lookup_table[field][\"Source Column\"]\n",
    "      default_value = lookup_table[field][\"Default Value\"]\n",
    "\n",
    "      if source_column:\n",
    "          if isinstance(source_column, list):\n",
    "              return \"_\".join([str(row.get(col, '')) for col in source_column])\n",
    "          return row.get(source_column, default_value)\n",
    "      return default_value\n",
    "\n",
    "def parse_to_hl7(df_input, lookup_table):\n",
    "\n",
    "    hl7_lines = []\n",
    "    obx_counter = {}\n",
    "    obr_counter = {}\n",
    "    empty_list = []\n",
    "    count = 0\n",
    "\n",
    "    for index, row in df_input.iterrows():\n",
    "\n",
    "      PatientMRN= row['PatientMRN']\n",
    "      if PatientMRN not in obr_counter:\n",
    "            obr_counter[PatientMRN] = 1\n",
    "      else:\n",
    "            obr_counter[PatientMRN] += 1\n",
    "\n",
    "      #Create MSH segment\n",
    "\n",
    "      msh_segment = [\n",
    "          f\"MSH|^~\\&|{get_value('MSH-3', row)}|{get_value('MSH-4', row)}|{get_value('MSH-5', row)}|{get_value('MSH-6', row)}|{get_value('MSH-7', row)}||{get_value('MSH-9', row)}|{get_value('MSH-10', row)}|{get_value('MSH-11', row)}|{get_value('MSH-12', row)}\"\n",
    "\n",
    "              ]\n",
    "\n",
    "      # Create PID segment\n",
    "      pid_segment = [\n",
    "                  f\"PID|||{get_value('PID-3.1', row)}^^^^{get_value('PID-3.5', row)}||{get_value('PID-5.1', row)}^{get_value('PID-5.2', row)}||{get_value('PID-7', row)}|{get_value('PID-8', row)}\"\n",
    "\n",
    "                  ]\n",
    "      # Create OBR segment\n",
    "      obr_segment = [\n",
    "\n",
    "                  f\"OBR|{obr_counter[PatientMRN]}||||||{get_value('OBR-3', row)}|||||||||{convert_to_int(get_value('OBR-7', row))}\"\n",
    "\n",
    "              ]\n",
    "        \n",
    "      obx_segment = [\n",
    "            f\"OBX|{obx_counter[RecordedDTTM]}||{row_get('LoincLabCode', row)}^{row_get('Metric_Abbr', row)}^LN||{row_get('Result', row)}|{row_get('Unit_Abbr', row)}\"\n",
    "        ]\n",
    "\n",
    "      hl7_message = \"\\n\".join(msh_segment + pid_segment + obr_segment + obx_segment)\n",
    "\n",
    "      hl7_lines.append(hl7_message)\n",
    "\n",
    "    return hl7_lines\n",
    "# Parse the input DataFrame to HL7 formatted output\n",
    "\n",
    "hl7_output = parse_to_hl7(df_input, lookup_table)\n",
    "# hl7_output\n",
    "\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    sanitized = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
    "    sanitized = sanitized.replace(' ', '_')\n",
    "    return sanitized\n",
    "\n",
    "\n",
    "def remove_duplicate_segments(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    unique_segments = {'MSH': False, 'PID': False, 'ORC': False, 'OBR': False}\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            segment_type = line.split('|')[0]\n",
    "            if segment_type in unique_segments:\n",
    "                if not unique_segments[segment_type]:\n",
    "                    file.write(line)\n",
    "                    unique_segments[segment_type] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "for index, row in df_input.iterrows():\n",
    "    filename = f\"{row['PatientMRN']}\"\n",
    "    sanitized_filename = sanitize_filename(filename)\n",
    "    file_path = f\"EPIC/{sanitized_filename}.hl7\"\n",
    "    file_paths.append(file_path)\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in hl7_output:\n",
    "                file.write(line + \"\\n\")\n",
    "\n",
    "for file_path in set(file_paths):\n",
    "    remove_duplicate_segments(file_path)\n",
    "\n",
    "\n",
    "\n",
    "print(hl7_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96edc0-45ab-4aea-b781-137cdd3507b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0d083be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HL7 messages have been written to output.txt.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the correct header manually based on the structure of your file\n",
    "headers = ['PatientId', 'Patient MRN', 'LastName', 'FirstName', 'MiddleName', 'DateOfBirth', 'Sex', 'Metric_Desc', \n",
    "           'Metric_Abbr', 'Result', 'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue', \n",
    "           'QOClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue', 'NumericFinding', 'Unit_Abbr', \n",
    "           'RecordedDTTM', 'QODE', 'Vital_Status', 'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode', \n",
    "           'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name', 'APM_Patient_Last_Name', 'APM_Patient_MI', \n",
    "           'APM_Patient_Street1', 'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State', \n",
    "           'APM_Patient_Zip_Code', 'APM_Patient_Country', 'APM_Patient_Sex', 'APM_Patient_DOB', \n",
    "           'Patient_Home_Phone', 'Patient_Work_Phone', 'Patient_Work_Ext', 'Patient_Cell_Phone', \n",
    "           'Patient_Primary_Phone_Type', 'Patient_Primary_Phone_Number', 'Patient_Emailx']\n",
    "\n",
    "def create_hl7_message(patient_id, rows):\n",
    "    # Create MSH segment (one per message)\n",
    "    msh_segment = f'MSH|^~\\\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|' \\\n",
    "                  f'{datetime.now().strftime(\"%Y%m%d%H%M%S\")}||ORU^R01|{patient_id}_{rows[0][\"ActivityHeaderID\"]}_{rows[0][\"PerformedDTTM\"].replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")}|P|2.5.1'\n",
    "\n",
    "    # Create PID segment (one per message)\n",
    "    pid_segment = f'PID|||{rows[0][\"Patient MRN\"]}^^^^TWSMAMRN||{rows[0][\"LastName\"]}^{rows[0][\"FirstName\"]}^{rows[0][\"MiddleName\"]}||' \\\n",
    "                  f'{rows[0][\"DateOfBirth\"].replace(\"-\", \"\")}|{rows[0][\"Sex\"]}|||{rows[0][\"APM_Patient_Street1\"]}^^{rows[0][\"APM_Patient_City\"]}^{rows[0][\"APM_Patient_State\"]}^{rows[0][\"APM_Patient_Zip_Code\"]}'\n",
    "\n",
    "    # Create OBR segment (one per message)\n",
    "    obr_segment = f'OBR|1||||||{rows[0][\"PerformedDTTM\"].replace(\"-\", \"\").replace(\" \", \"\").replace(\":\", \"\")}'\n",
    "\n",
    "    # Create OBX segments (multiple per message)\n",
    "    obx_segments = []\n",
    "    for idx, row in enumerate(rows, start=1):\n",
    "        obx_segment = f'OBX|{idx}||{row[\"LoincLabCode\"]}^{row[\"Metric_Abbr\"]}^LN||{row[\"Result\"]}|{row[\"UnitOfMeasure\"]}'\n",
    "        obx_segments.append(obx_segment)\n",
    "\n",
    "    # Combine all segments\n",
    "    hl7_message = f'{msh_segment}\\n{pid_segment}\\n{obr_segment}\\n' + '\\n'.join(obx_segments) + '\\n'\n",
    "\n",
    "    return hl7_message\n",
    "\n",
    "def convert_to_hl7(input_file, output_file):\n",
    "    # Open the CSV file and the output file\n",
    "    with open(input_file, mode='r') as infile, open(output_file, mode='w') as outfile:\n",
    "        csv_reader = csv.DictReader(infile, delimiter='|', fieldnames=headers)\n",
    "\n",
    "        # Initialize variables for processing multiple OBX rows per message\n",
    "        current_patient = None\n",
    "        rows_for_patient = []\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if row['PatientId'] != current_patient:\n",
    "                # If we have collected rows for a patient, process them\n",
    "                if rows_for_patient:\n",
    "                    hl7_message = create_hl7_message(current_patient, rows_for_patient)\n",
    "                    outfile.write(hl7_message + '\\n')\n",
    "                \n",
    "                # Start collecting rows for the new patient\n",
    "                current_patient = row['PatientId']\n",
    "                rows_for_patient = [row]\n",
    "            else:\n",
    "                # Continue collecting rows for the same patient\n",
    "                rows_for_patient.append(row)\n",
    "\n",
    "        # Process the last patient\n",
    "        if rows_for_patient:\n",
    "            hl7_message = create_hl7_message(current_patient, rows_for_patient)\n",
    "            outfile.write(hl7_message + '\\n')\n",
    "\n",
    "# Example usage\n",
    "input_file = 'Input.txt'  # Replace with your input file path\n",
    "output_file = 'output.txt'  # Replace with your desired output file path\n",
    "convert_to_hl7(input_file, output_file)\n",
    "\n",
    "print(f\"HL7 messages have been written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba85d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HL7 messages have been written to output.txt.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the correct header manually based on the structure of your file\n",
    "headers = ['PatientId', 'Patient MRN', 'LastName', 'FirstName', 'MiddleName', 'DateOfBirth', 'Sex', 'Metric_Desc', \n",
    "           'Metric_Abbr', 'Result', 'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue', \n",
    "           'QOClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue', 'NumericFinding', 'Unit_Abbr', \n",
    "           'RecordedDTTM', 'QODE', 'Vital_Status', 'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode', \n",
    "           'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name', 'APM_Patient_Last_Name', 'APM_Patient_MI', \n",
    "           'APM_Patient_Street1', 'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State', 'APM_Patient_Zip_Code', \n",
    "           'APM_Patient_Country', 'APM_Patient_Sex', 'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone', \n",
    "           'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type', 'Patient_Primary_Phone_Number', \n",
    "           'Patient_Emailx']\n",
    "\n",
    "def create_hl7_message(row, patient_id):\n",
    "    # Create MSH segment\n",
    "    msh_segment = f'MSH|^~\\\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|{datetime.now().strftime(\"%Y%m%d%H%M%S\")}||ORU^R01|{patient_id}_{row[\"ActivityHeaderID\"]}_{row[\"PerformedDTTM\"].replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")}|P|2.5.1'\n",
    "\n",
    "    # Create PID segment\n",
    "    pid_segment = f'PID|||{row[\"Patient MRN\"]}^^^^TWSMAMRN||{row[\"LastName\"]}^{row[\"FirstName\"]}^{row[\"MiddleName\"]}||{row[\"DateOfBirth\"].replace(\"-\", \"\")}|{row[\"Sex\"]}|||{row[\"APM_Patient_Street1\"]}^^{row[\"APM_Patient_City\"]}^{row[\"APM_Patient_State\"]}^{row[\"APM_Patient_Zip_Code\"]}'\n",
    "\n",
    "    # Create OBR segment\n",
    "    obr_segment = f'OBR|1||||||{row[\"PerformedDTTM\"].replace(\"-\", \"\").replace(\" \", \"\").replace(\":\", \"\")}'\n",
    "\n",
    "    # Combine initial segments\n",
    "    hl7_message = f'{msh_segment}\\n{pid_segment}\\n{obr_segment}\\n'\n",
    "    \n",
    "    return hl7_message\n",
    "\n",
    "def add_obx_segments(rows):\n",
    "    obx_segments = \"\"\n",
    "    for i, row in enumerate(rows):\n",
    "        obx_segment = f'OBX|{i+1}||{row[\"LoincLabCode\"]}^{row[\"Metric_Abbr\"]}^LN||{row[\"Result\"]}|{row[\"UnitOfMeasure\"]}'\n",
    "        obx_segments += obx_segment + \"\\n\"\n",
    "    \n",
    "    return obx_segments\n",
    "\n",
    "def convert_to_hl7(input_file, output_file):\n",
    "    with open(input_file, mode='r') as infile, open(output_file, mode='w') as outfile:\n",
    "        csv_reader = csv.DictReader(infile, delimiter='|', fieldnames=headers)\n",
    "        \n",
    "        # Skip the first row since it’s the actual data row, not a header\n",
    "        next(csv_reader)\n",
    "        \n",
    "        # Temporary variables to track unique patients\n",
    "        current_patient_id = None\n",
    "        patient_data = []\n",
    "\n",
    "        for row in csv_reader:\n",
    "            patient_id = row[\"Patient MRN\"]\n",
    "            \n",
    "            # If patient changes, output the previous patient's data\n",
    "            if current_patient_id and patient_id != current_patient_id:\n",
    "                hl7_message = create_hl7_message(patient_data[0], current_patient_id)\n",
    "                hl7_message += add_obx_segments(patient_data)\n",
    "                outfile.write(hl7_message + '\\n')\n",
    "                \n",
    "                # Clear patient data\n",
    "                patient_data = []\n",
    "\n",
    "            # Update current patient ID and append data\n",
    "            current_patient_id = patient_id\n",
    "            patient_data.append(row)\n",
    "\n",
    "        # Write the last patient's data\n",
    "        if patient_data:\n",
    "            hl7_message = create_hl7_message(patient_data[0], current_patient_id)\n",
    "            hl7_message += add_obx_segments(patient_data)\n",
    "            outfile.write(hl7_message + '\\n')\n",
    "\n",
    "# Example usage inside a Jupyter notebook\n",
    "input_file = 'Input.txt'  # Replace with your input file path\n",
    "output_file = 'output.txt'  # Replace with your desired output file path\n",
    "convert_to_hl7(input_file, output_file)\n",
    "\n",
    "# Display confirmation that the process is done\n",
    "print(f\"HL7 messages have been written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c2425d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HL7 message for patient 20004200 has been written to output.txt.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the correct header manually based on the structure of your file\n",
    "headers = ['PatientId', 'Patient MRN', 'LastName', 'FirstName', 'MiddleName', 'DateOfBirth', 'Sex', 'Metric_Desc', \n",
    "           'Metric_Abbr', 'Result', 'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue', \n",
    "           'QOClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue', 'NumericFinding', 'Unit_Abbr', \n",
    "           'RecordedDTTM', 'QODE', 'Vital_Status', 'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode', \n",
    "           'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name', 'APM_Patient_Last_Name', 'APM_Patient_MI', \n",
    "           'APM_Patient_Street1', 'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State', 'APM_Patient_Zip_Code', \n",
    "           'APM_Patient_Country', 'APM_Patient_Sex', 'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone', \n",
    "           'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type', 'Patient_Primary_Phone_Number', \n",
    "           'Patient_Emailx']\n",
    "\n",
    "def create_hl7_message(row):\n",
    "    # Create MSH segment\n",
    "    msh_segment = f'MSH|^~\\\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|{datetime.now().strftime(\"%Y%m%d%H%M%S\")}||ORU^R01|{row[\"Patient MRN\"]}_{row[\"ActivityHeaderID\"]}_{row[\"PerformedDTTM\"].replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")}|P|2.5.1'\n",
    "\n",
    "    # Create PID segment\n",
    "    pid_segment = f'PID|||{row[\"Patient MRN\"]}^^^^TWSMAMRN||{row[\"LastName\"]}^{row[\"FirstName\"]}^{row[\"MiddleName\"]}||{row[\"DateOfBirth\"].replace(\"-\", \"\")}|{row[\"Sex\"]}|||{row[\"APM_Patient_Street1\"]}^^{row[\"APM_Patient_City\"]}^{row[\"APM_Patient_State\"]}^{row[\"APM_Patient_Zip_Code\"]}'\n",
    "\n",
    "    # Create OBR segment\n",
    "    obr_segment = f'OBR|1||||||{row[\"PerformedDTTM\"].replace(\"-\", \"\").replace(\" \", \"\").replace(\":\", \"\")}'\n",
    "\n",
    "    # Combine initial segments\n",
    "    hl7_message = f'{msh_segment}\\n{pid_segment}\\n{obr_segment}\\n'\n",
    "    \n",
    "    return hl7_message\n",
    "\n",
    "def add_obx_segments(rows):\n",
    "    obx_segments = \"\"\n",
    "    for i, row in enumerate(rows):\n",
    "        obx_segment = f'OBX|{i+1}||{row[\"LoincLabCode\"]}^{row[\"Metric_Abbr\"]}^LN||{row[\"Result\"]}|{row[\"UnitOfMeasure\"]}'\n",
    "        obx_segments += obx_segment + \"\\n\"\n",
    "    \n",
    "    return obx_segments\n",
    "\n",
    "def convert_to_hl7_for_one_patient(input_file, output_file, target_patient_mrn):\n",
    "    with open(input_file, mode='r') as infile, open(output_file, mode='w') as outfile:\n",
    "        csv_reader = csv.DictReader(infile, delimiter='|', fieldnames=headers)\n",
    "        \n",
    "        # Skip the first row since it’s the actual data row, not a header\n",
    "        next(csv_reader)\n",
    "        \n",
    "        patient_data = []\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            patient_id = row[\"Patient MRN\"]\n",
    "            \n",
    "            # Only process data for the target patient\n",
    "            if patient_id == target_patient_mrn:\n",
    "                patient_data.append(row)\n",
    "\n",
    "        # Write the target patient's data to HL7 if found\n",
    "        if patient_data:\n",
    "            hl7_message = create_hl7_message(patient_data[0])\n",
    "            hl7_message += add_obx_segments(patient_data)\n",
    "            outfile.write(hl7_message + '\\n')\n",
    "        else:\n",
    "            print(f\"No data found for patient MRN: {target_patient_mrn}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = 'Input.txt'  # Input file path\n",
    "output_file = 'output.txt'  # Output file path\n",
    "target_patient_mrn = '20004200'  # The specific Patient MRN you're interested in\n",
    "convert_to_hl7_for_one_patient(input_file, output_file, target_patient_mrn)\n",
    "\n",
    "# Display confirmation\n",
    "print(f\"HL7 message for patient {target_patient_mrn} has been written to {output_file}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8b289b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HL7 messages have been written to output.hl7.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the correct header manually based on the structure of your input file\n",
    "headers = ['PatientId', 'Patient MRN', 'LastName', 'FirstName', 'MiddleName', 'DateOfBirth', 'Sex', 'Metric_Desc', \n",
    "           'Metric_Abbr', 'Result', 'UnitOfMeasure', 'CreateDTTM', 'PerformedDTTM', 'DecodedValue', \n",
    "           'QOClassificationDE', 'AnswerDE', 'VitalValue', 'NormalizedValue', 'NumericFinding', 'Unit_Abbr', \n",
    "           'RecordedDTTM', 'QODE', 'Vital_Status', 'Mode_Name', 'ActivityHeaderID', 'ItemID', 'LoincLabCode', \n",
    "           'APM_Patient_ID', 'APM_MRN', 'APM_Patient_First_Name', 'APM_Patient_Last_Name', 'APM_Patient_MI', \n",
    "           'APM_Patient_Street1', 'APM_Patient_Street2', 'APM_Patient_City', 'APM_Patient_State', 'APM_Patient_Zip_Code', \n",
    "           'APM_Patient_Country', 'APM_Patient_Sex', 'APM_Patient_DOB', 'Patient_Home_Phone', 'Patient_Work_Phone', \n",
    "           'Patient_Work_Ext', 'Patient_Cell_Phone', 'Patient_Primary_Phone_Type', 'Patient_Primary_Phone_Number', \n",
    "           'Patient_Emailx']\n",
    "\n",
    "def create_msh_segment(row):\n",
    "    # MSH segment with current date and unique message control ID\n",
    "    return f'MSH|^~\\\\&|TouchWorks|Southwest Medical Associates|Rhapsody^Rhapsody|Epic^Epic|{datetime.now().strftime(\"%Y%m%d%H%M%S\")}||ORU^R01|{row[\"Patient MRN\"]}_{row[\"ActivityHeaderID\"]}_{row[\"PerformedDTTM\"].replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")}|P|2.5.1'\n",
    "\n",
    "def create_pid_segment(row):\n",
    "    # PID segment for patient identification\n",
    "    return f'PID|||{row[\"Patient MRN\"]}^^^^TWSMAMRN||{row[\"LastName\"]}^{row[\"FirstName\"]}^{row[\"MiddleName\"]}||{row[\"DateOfBirth\"].replace(\"-\", \"\")}|{row[\"Sex\"]}|||{row[\"APM_Patient_Street1\"]}^^{row[\"APM_Patient_City\"]}^{row[\"APM_Patient_State\"]}^{row[\"APM_Patient_Zip_Code\"]}'\n",
    "\n",
    "def create_obr_segment(row):\n",
    "    # OBR segment for observation request\n",
    "    return f'OBR|1||||||{row[\"PerformedDTTM\"].replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")}'\n",
    "\n",
    "def create_obx_segment(row, index, loinc_code, observation_desc, result, unit):\n",
    "    # OBX segment for observations\n",
    "    return f'OBX|{index}||{loinc_code}^{observation_desc}^LN||{result}|{unit}'\n",
    "\n",
    "def process_patient_data(rows):\n",
    "    hl7_messages = []\n",
    "    for row in rows:\n",
    "        msh_segment = create_msh_segment(row)\n",
    "        pid_segment = create_pid_segment(row)\n",
    "        obr_segment = create_obr_segment(row)\n",
    "        \n",
    "        obx_segments = []\n",
    "        observations = [\n",
    "            {\"loinc_code\": \"8480-6\", \"desc\": \"BP SYS\", \"result\": row[\"Result\"], \"unit\": row[\"UnitOfMeasure\"]},\n",
    "            {\"loinc_code\": \"8462-4\", \"desc\": \"BP DIAS\", \"result\": row[\"Result\"], \"unit\": row[\"UnitOfMeasure\"]},\n",
    "            {\"loinc_code\": \"59574-4\", \"desc\": \"BMIPerc\", \"result\": row[\"Result\"], \"unit\": row[\"UnitOfMeasure\"]},\n",
    "            # Add more observations as needed\n",
    "        ]\n",
    "\n",
    "        for i, obs in enumerate(observations, start=1):\n",
    "            obx_segment = create_obx_segment(row, i, obs[\"loinc_code\"], obs[\"desc\"], obs[\"result\"], obs[\"unit\"])\n",
    "            obx_segments.append(obx_segment)\n",
    "\n",
    "        # Combine segments into one HL7 message\n",
    "        hl7_message = f'{msh_segment}\\n{pid_segment}\\n{obr_segment}\\n' + '\\n'.join(obx_segments) + '\\n'\n",
    "        hl7_messages.append(hl7_message)\n",
    "    \n",
    "    return hl7_messages\n",
    "\n",
    "def convert_to_hl7(input_file, output_file):\n",
    "    with open(input_file, mode='r') as infile, open(output_file, mode='w') as outfile:\n",
    "        csv_reader = csv.DictReader(infile, delimiter='|', fieldnames=headers)\n",
    "        \n",
    "        # Skip the first row (if it's a header)\n",
    "        next(csv_reader)\n",
    "        \n",
    "        # Process each row to generate HL7 messages\n",
    "        hl7_messages = process_patient_data(csv_reader)\n",
    "        \n",
    "        # Write the generated HL7 messages to the output file\n",
    "        for hl7_message in hl7_messages:\n",
    "            outfile.write(hl7_message + '\\n')\n",
    "\n",
    "# Example usage inside a Jupyter notebook or Python script\n",
    "input_file = 'Input.txt'  # Replace with your input file path\n",
    "output_file = 'output.hl7'  # Replace with your desired output file path\n",
    "convert_to_hl7(input_file, output_file)\n",
    "\n",
    "# Display confirmation that the process is done\n",
    "print(f\"HL7 messages have been written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ddc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
